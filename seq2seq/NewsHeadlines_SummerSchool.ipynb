{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate News Headlines using RNN\n",
    "We will use the kaggle Indian news headline dataset (https://www.kaggle.com/therohk/india-headlines-news-dataset).<br/>\n",
    "A cleaned dataset of 100,000 is produced from this. We want to generate new headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes! GPU!\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "if use_cuda:\n",
    "    print('Yes! GPU!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "with open('news-headlines-trimmed.txt') as f:\n",
    "    data = f.read()\n",
    "\n",
    "data = data.split('\\n')[:1000] # fast training\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start of Sentence (SOS) is added to the begining of every headline. <br/>\n",
    "End of Sentence (EOS) is to indicate when to stop generating characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOS = 0\n",
    "EOS = 127"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode sentence as sequence of one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "def one_hotter(c):\n",
    "    vec = torch.zeros(128)\n",
    "    vec[ord(c)] = 1.0\n",
    "    return vec\n",
    "\n",
    "def encode_sentence(s):\n",
    "    v = torch.zeros(1, len(s)+1, 128)\n",
    "    \n",
    "    # append SOS\n",
    "    vec = torch.zeros(128)\n",
    "    vec[SOS] = 1.0\n",
    "    v[0, 0, :] = vec\n",
    "    \n",
    "    for i in range(len(s)):\n",
    "        v[0, i+1, :] = one_hotter(s[i])\n",
    "        \n",
    "    # append EOS\n",
    "    # vec = torch.zeros(128)\n",
    "    # vec[EOS] = 1.0\n",
    "    # v[0, len(s)+1, :] = vec\n",
    "    \n",
    "    return v.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e = encode_sentence('ab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RnnNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(RnnNet, self).__init__()\n",
    "        self.input_dim = 128 # one-hot encoding of ascii \n",
    "        # self.seq_len = 28\n",
    "        self.hidden_dim = 100\n",
    "        self.batch_size = 1 # sorry! variable length sentences. \n",
    "        # We can pad and make batches though. But let's stick to simplicity\n",
    "        self.num_class = self.input_dim\n",
    "        \n",
    "        self.rnn = nn.GRU(self.input_dim, self.hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(self.hidden_dim, self.num_class)\n",
    "\n",
    "    def forward(self, x, h0):\n",
    "        \n",
    "        # h0 = torch.randn(1, self.batch_size, self.hidden_dim).to(device)\n",
    "        # run the LSTM along the sequences of length seq_len\n",
    "        \n",
    "        x, h = self.rnn(x, h0)      # dim: batch_size x seq_len x hidden_dim\n",
    "        \n",
    "        # make the Variable contiguous in memory (a PyTorch artefact)\n",
    "        x = x.contiguous()\n",
    "\n",
    "        # reshape the Variable so that each row contains one token\n",
    "        x = x.view(-1, x.shape[2])       # dim: batch_size*seq_len x hidden_dim (note batch_size=1)\n",
    "\n",
    "        # apply the fully connected layer and obtain the output (before softmax) for each token\n",
    "        x = self.fc(x)                   # dim: batch_size*seq_len x num_class\n",
    "\n",
    "        # apply log softmax on each token's output (this is recommended over applying softmax\n",
    "        # since it is numerically more stable)\n",
    "        return F.log_softmax(x, dim=1), h   # dim: batch_size*seq_len x num_class & dim(h): 1 x 1(batch) x hidden_dim\n",
    "    \n",
    "    def genh(self):\n",
    "        return torch.randn(1, self.batch_size, self.hidden_dim).to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RnnNet().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "import logging\n",
    "\n",
    "# logging.basicConfig(format='%(asctime)s [%(levelname)-8s] %(message)s')\n",
    "# logger = logging.getLogger()\n",
    "# logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_headlines(num=5):\n",
    "    model.eval()\n",
    "    \n",
    "    for i in range(num):\n",
    "        gen= ''\n",
    "        h = model.genh()\n",
    "        i = 0\n",
    "        prev = torch.zeros(1, 1, 128).to(device)\n",
    "        prev[0,0,0] = 1.0\n",
    "        \n",
    "        while(True):\n",
    "            output, h = model(prev, h)\n",
    "            s = torch.argmax(output, dim=1)\n",
    "\n",
    "            # Stop if EOS is generated\n",
    "            if s == 127:\n",
    "                continue\n",
    "\n",
    "            # update generated sentence\n",
    "            gen += chr(s)    \n",
    "            prev = torch.zeros(1, 1, 128).to(device)\n",
    "            prev[0,0,s] = 1.0\n",
    "\n",
    "            i += 1\n",
    "            if i > 200:\n",
    "                break\n",
    "\n",
    "        print(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 37/10000 [00:00<00:27, 367.59it/s, loss=4.855]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:23<00:00, 433.20it/s, loss=2.169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shar har stade to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be \n",
      "'P to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be \n",
      "Govt to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 42/10000 [00:00<00:23, 418.13it/s, loss=2.491]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooll to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to \n",
      "Pand hard for stade to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be t\n",
      "\n",
      "epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:23<00:00, 433.01it/s, loss=2.168]\n",
      "  0%|          | 42/10000 [00:00<00:23, 416.87it/s, loss=2.459]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cong to be the reside in Pan\n",
      "Shara has to be the reside in Pan\n",
      "Shara has to be the reside in Pan\n",
      "'Phoolan Shar to be the reside in Pan\n",
      "Pake to be the reside in Pan\n",
      "\n",
      "epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:23<00:00, 432.69it/s, loss=2.152]\n",
      "  0%|          | 42/10000 [00:00<00:23, 415.63it/s, loss=2.453]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shoking to be the residents in Pan\n",
      "Cong to be the residents in Pan\n",
      "Phoolan secured in Pan to be the residents\n",
      "'Phoolan secured in the reside in Manaphar\n",
      "Shooti secured in Pan to be the residents\n",
      "\n",
      "epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:23<00:00, 432.49it/s, loss=1.986]\n",
      "  0%|          | 42/10000 [00:00<00:23, 417.20it/s, loss=2.458]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another states to be the be to be the be to security state\n",
      "Phoolan security seeks for the be to be the be to security state\n",
      "Sharat has to be the be to be the be to security state\n",
      "Sharat has to be the be to be the be to security state\n",
      "Seet of the decision of strike\n",
      "\n",
      "epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:23<00:00, 432.91it/s, loss=1.933]\n",
      "  0%|          | 42/10000 [00:00<00:23, 416.83it/s, loss=2.437]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharan header in the residents\n",
      "'Phoolan security seeks for the be to security conserves\n",
      "Phoolan security seeks for the be to security conserves\n",
      "Sharat have to be the be to security conserves\n",
      "Sharat have to be the be to security conserves\n",
      "\n",
      "epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:23<00:00, 433.14it/s, loss=1.908]\n",
      "  0%|          | 42/10000 [00:00<00:23, 417.45it/s, loss=2.442]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Phoolan security states in Pan joing to be the seek in Pan\n",
      "State to be the be to be the seek in Pan\n",
      "Phoolan security states in Pan joing to be the seek in Pan\n",
      "Phoolan security states in Panaji\n",
      "Shah have to be the be to be the seek in Pan\n",
      "\n",
      "epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:23<00:00, 432.31it/s, loss=1.876]\n",
      "  0%|          | 42/10000 [00:00<00:23, 417.61it/s, loss=2.375]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State to be the be to protest of Phoolan's conserves\n",
      "Shah a can to be residents to be resident\n",
      "Sharat have to be recovered in Phoolan's conserves\n",
      "State to be the be to protest of Phoolan's conserves\n",
      "'Phoolan seeks for the be to protest of Phoolan's conserves\n",
      "\n",
      "epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:23<00:00, 432.65it/s, loss=1.830]\n",
      "  0%|          | 42/10000 [00:00<00:23, 418.47it/s, loss=2.388]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shah a can to be residents to be residents\n",
      "Shah a case of the be the best\n",
      "Shah a can to be residents to be residents\n",
      "Phoolan seeks for Phoolan seeks for dead\n",
      "'I dead in Manipur to be residents\n",
      "\n",
      "epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:23<00:00, 433.12it/s, loss=1.781]\n",
      "  0%|          | 42/10000 [00:00<00:23, 417.48it/s, loss=2.400]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State to be residents to be residents\n",
      "Cong seeks for Phoolan seeks for Phoolan's conservation\n",
      "Shah to death in Manipur\n",
      "State hard to be residents state in Pan\n",
      "Phoolan seeks for Phoolan seeks for Phoolan's conservation\n",
      "\n",
      "epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:23<00:00, 432.27it/s, loss=1.776]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State hard to be read to be restrice\n",
      "State hard to be read to be restrice\n",
      "Cong seeks for Phoolan seek to be service\n",
      "'Chargesh in the residents state in Phoolan's conservation\n",
      "Phoolan seeks for a construction of the residents\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # Use tqdm for progress bar\n",
    "    t = trange(len(data)) \n",
    "    print('\\nepoch {}/{}'.format(epoch+1, epochs))\n",
    "    for i in t:\n",
    "        # Get the representation of sentence\n",
    "        d = data[i]\n",
    "        d = d.strip()\n",
    "        if len(d) == 0: # empty sentences are not allowed\n",
    "            break\n",
    "\n",
    "        enc_sen = encode_sentence(d)\n",
    "        h0 = model.genh()\n",
    "        output, _ = model(enc_sen, h0) # dim: seq_len x num_class\n",
    "        target = [ord(c) for c in d] + [EOS]\n",
    "        target = torch.LongTensor(target).to(device)\n",
    "\n",
    "        # zero param grads\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i%100 == 0:\n",
    "            t.set_postfix(loss='{:05.3f}'.format(loss.item()))\n",
    "    \n",
    "    # print samples from the language model\n",
    "    gen_headlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo\n",
    "1. While generating, sample instead of argmax for next character\n",
    "2. Use multiple layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step by Step\n",
      "Hawkings' day out\n",
      "Dill sects police reality of thrents puckes\n",
      "'sertt to a plast to a with polority\n",
      "Hawkings' day out\n"
     ]
    }
   ],
   "source": [
    "gen_headlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [pytorch]",
   "language": "python",
   "name": "Python [pytorch]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
